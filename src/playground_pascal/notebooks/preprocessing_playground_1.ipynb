{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Playground\n",
    "How to get a tf vector for each document \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/Users/pascalweiss/dev/python/dl_project_gl_pw/src\")\n",
    "\n",
    "from src.preprocessing.preprocessing import Preprocessing\n",
    "from src.preprocessing.cleaning import Cleaning\n",
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from spacy.attrs import ORTH, LEMMA\n",
    "from collections import Counter\n",
    "\n",
    "pd.options.display.max_colwidth = 0\n",
    "pd.options.display.expand_frame_repr = False\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "source": [
    "pp = Preprocessing()\n",
    "pp.load_data('../data/comments_cleaned.txt', '../data/annotation.txt')\n",
    "df = pp.get_data_df(deep_copy=False)[:1000]\n",
    "cl = Cleaning(df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "source": [
    "foodata = [\n",
    "    [\"this\", \"is\", \"really\", \"really\", \"a\", \"document\"],\n",
    "    [\"this\", \"is\", \"another\"],\n",
    "    [\"completely\", \"new\"]\n",
    "]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "source": [
    "def _flatten(list_of_lists):\n",
    "    return [el for l in list_of_lists for el in l]\n",
    "\n",
    "\n",
    "words = _flatten(foodata)\n",
    "word_freq = Counter(words)\n",
    "{x: word_freq[x] for x in word_freq if word_freq[x] >= 1}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "source": [
    "common_words"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Removing stop words, removing punctuation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "rules = Cleaning.get_cleaning_rules(\n",
    "    remove_stop=False,\n",
    "    remove_punctuation=True,\n",
    "    word_white_list=['!'],\n",
    "    special_cases=[{'token': '&amp', 'replacement': [{ORTH: '&amp', LEMMA: 'and'}]}])\n",
    "\n",
    "cl.apply_on_cols(cols=['post', 'reply'], cleaning_rules=rules, join_strings=False, n_threads=-1, batch_size=100)\n",
    "df_c = cl.get_df()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "pp.set_data_df(df_c, deep_copy=False)\n",
    "pp.split_in_train_test()\n",
    "df_train = pp.get_train_df(deep_copy=False)\n",
    "df_test = pp.get_test_df(deep_copy=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "dictionary = corpora.Dictionary(df_test.reply)\n",
    "raw_corpus = [dictionary.doc2bow(d) for d in df_test.reply]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "source": [
    "df_test"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "foodata = [\n",
    "    [\"this\", \"is\", \"really\", \"really\", \"a\", \"document\"],\n",
    "    [\"this\", \"is\", \"another\"],\n",
    "    [\"completely\", \"new\"]\n",
    "]\n",
    "foodict = corpora.Dictionary(foodata)\n",
    "foocorpus = [foodict.doc2bow(d) for d in foodata]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "foocorpus"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "gensim.matutils.corpus2dense(foocorpus, num_terms=len(foodict)).T\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "tfidf = models.TfidfModel(foocorpus)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "source": [
    "gensim.matutils.corpus2dense(tfidf[foocorpus], num_terms=len(foodict)).T"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv353",
   "language": "python",
   "name": "venv353"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
