{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/Users/pascalweiss/dev/python/dl_project_gl_pw/\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "from scipy import stats\n",
    "from src.preprocessing.preprocessing import Preprocessing\n",
    "from src.preprocessing.datahandler import DataHandler\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_colwidth = 0\n",
    "pd.options.display.expand_frame_repr = False\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "\n",
    "dh = DataHandler()\n",
    "dh.load_data('data/comments_cleaned.txt', 'data/annotation.txt')\n",
    "df = dh.get_data_df(deep_copy=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "pp = Preprocessing(model_type='en')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "source": [
    "piped = pp.run_spacy_pipeline(df.reply[:100])\n",
    "reply = pp.filter_spacy_tokens(piped, no_punctuation=False, no_stop_words=False)\n",
    "reply = pp.convert_token_docs_text(reply, token_kind='lemma_')\n",
    "reply = pp.inner_str_join_2d_list(reply)\n",
    "tfidf = pp.str_list_to_tfidf(reply, min_df=1, ngram_range=(1, 1))\n",
    "data = tfidf.data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "source": [
    "count, x = np.histogram(data, bins=100)\n",
    "x = x[:len(count)]\n",
    "idx = np.arange(len(x))\n",
    "\n",
    "bar_width = 1.0\n",
    "\n",
    "plt.bar(idx, count, bar_width)\n",
    "plt.xticks([], [])\n",
    "plt.show()\n",
    "print(\"shape: \", data.shape, stats.describe(data))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "source": [
    "v = Variable(torch.FloatTensor(data.reshape(1, len(data))))\n",
    "data_norm = F.normalize(v)\n",
    "data_norm_np = data_norm.data.numpy()\n",
    "\n",
    "count, x = np.histogram(data_norm_np, bins=100)\n",
    "x = x[:len(count)]\n",
    "idx = np.arange(len(x))\n",
    "\n",
    "bar_width = 1.0\n",
    "\n",
    "plt.bar(idx, count, bar_width)\n",
    "plt.xticks([], [])\n",
    "plt.show()\n",
    "print(stats.describe(data_norm_np.reshape(len(data), )))\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "source": [
    "batch = Variable(\n",
    "    torch.FloatTensor([\n",
    "        (0.1, 0.7, 0.3, 0.9, 0.01, 0.4),\n",
    "        (10, 21, 4, 0.5, 0.2, 9)\n",
    "    ])\n",
    ")\n",
    "\n",
    "norm1 = F.normalize(batch)\n",
    "norm2 = F.normalize(batch[:1])\n",
    "norm3 = F.normalize(batch[1:2])\n",
    "norm1, norm2, norm3"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "source": [
    "class DatasetTfIdf(Dataset):\n",
    "    def __init__(self, tfidf):\n",
    "        self.tfidf = tfidf\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tfidf.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = torch.FloatTensor(\n",
    "            self.tfidf[idx,].todense()\n",
    "        )\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "ds = DatasetTfIdf(tfidf)\n",
    "dl = DataLoader(ds, batch_size=2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access all elements WITH normalization and meassure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%%time\n",
    "for idx, batch in enumerate(dl):\n",
    "    # some arbitrary operation\n",
    "    b = Variable(batch)\n",
    "    # normalize and do something arbitrary \n",
    "    F.normalize(b).sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access all elements WITHOUT normalization and meassure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "source": [
    "%%time\n",
    "for idx, batch in enumerate(dl):\n",
    "    # some arbitrary operation\n",
    "    b = Variable(batch)\n",
    "    # normalize and do something arbitrary \n",
    "    b.sum()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
